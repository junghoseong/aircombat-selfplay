{"value_loss": 0.0007208157468994614, "_timestamp": 1735380156.7466028, "policy_loss": -0.0014519511547405272, "policy_entropy_loss": -0.000596160301938653, "actor_grad_norm": 0.224453704059124, "critic_grad_norm": 0.8085782691836357, "ratio": 1.0003590136766434, "average_episode_rewards": NaN, "_runtime": 208.23993372917175, "_step": 72000, "_wandb": {"runtime": 450}, "eval_average_episode_rewards": -185.10012817382812, "latest_elo": 1000.0}